"""
Demo Script for Multilingual RAG System
Demonstrates the complete workflow with sample data
"""

import os
import sys
import json
from datetime import datetime

# Add src to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from src.multilingual_rag import MultilingualRAG
from src.evaluation import run_evaluation

def create_sample_text_file():
    """Create a sample text file with Bengali content for testing"""
    sample_content = """
ржЕржирзБржкржо ржЪрж░рж┐рждрзНрж░ ржмрж┐рж╢рзНрж▓рзЗрж╖ржг

ржЕржирзБржкржорзЗрж░ ржнрж╛рж╖рж╛ржпрж╝ рж╕рзБржкрзБрж░рзБрж╖ ржХрж╛ржХрзЗ ржмрж▓рж╛ рж╣ржпрж╝рзЗржЫрзЗ? ржЕржирзБржкржорзЗрж░ ржнрж╛рж╖рж╛ржпрж╝ рж╕рзБржкрзБрж░рзБрж╖ ржмрж▓рждрзЗ рж╢рзБржорзНржнрзБржирж╛ржержХрзЗ ржмрзЛржЭрж╛ржирзЛ рж╣ржпрж╝рзЗржЫрзЗред рж╢рзБржорзНржнрзБржирж╛рже ржПржХржЬржи ржЖржжрж░рзНрж╢ ржкрзБрж░рзБрж╖ рж╣рж┐рж╕рзЗржмрзЗ ржЪрж┐рждрзНрж░рж┐ржд рж╣ржпрж╝рзЗржЫрзЗржиред

ржХрж╛ржХрзЗ ржЕржирзБржкржорзЗрж░ ржнрж╛ржЧрзНржп ржжрзЗржмрждрж╛ ржмрж▓рзЗ ржЙрж▓рзНрж▓рзЗржЦ ржХрж░рж╛ рж╣ржпрж╝рзЗржЫрзЗ? ржЕржирзБржкржорзЗрж░ ржорж╛ржорж╛ржХрзЗ рждрж╛рж░ ржнрж╛ржЧрзНржп ржжрзЗржмрждрж╛ ржмрж▓рзЗ ржЙрж▓рзНрж▓рзЗржЦ ржХрж░рж╛ рж╣ржпрж╝рзЗржЫрзЗред ржорж╛ржорж╛ ржЕржирзБржкржорзЗрж░ ржЬрзАржмржирзЗ ржЧрзБрж░рзБрждрзНржмржкрзВрж░рзНржг ржнрзВржорж┐ржХрж╛ ржкрж╛рж▓ржи ржХрж░рзЗржЫрзЗржиред

ржмрж┐ржпрж╝рзЗрж░ рж╕ржоржпрж╝ ржХрж▓рзНржпрж╛ржгрзАрж░ ржкрзНрж░ржХрзГржд ржмржпрж╝рж╕ ржХржд ржЫрж┐рж▓? ржмрж┐ржпрж╝рзЗрж░ рж╕ржоржпрж╝ ржХрж▓рзНржпрж╛ржгрзАрж░ ржкрзНрж░ржХрзГржд ржмржпрж╝рж╕ ржЫрж┐рж▓ ржорж╛рждрзНрж░ рззрзл ржмржЫрж░ред ржПржЯрж┐ рж╕рзЗржЗ рж╕ржоржпрж╝рзЗрж░ рж╕рж╛ржорж╛ржЬрж┐ржХ ржкрзНрж░ржерж╛рж░ ржПржХржЯрж┐ ржЙржжрж╛рж╣рж░ржгред

ржЪрж░рж┐рждрзНрж░ ржмрж┐рж╢рзНрж▓рзЗрж╖ржг:
ржЕржирзБржкржо ржПржХржЬржи рж╢рж┐ржХрзНрж╖рж┐ржд ржпрзБржмржХ ржпрж┐ржирж┐ рждрж╛рж░ рж╕ржоржпрж╝рзЗрж░ рж╕рж╛ржорж╛ржЬрж┐ржХ рж╕ржорж╕рзНржпрж╛ ржирж┐ржпрж╝рзЗ ржЪрж┐ржирзНрждрж╛ ржХрж░рзЗржиред рждрж┐ржирж┐ ржмрж┐ржмрж╛рж╣рзЗрж░ ржХрзНрж╖рзЗрждрзНрж░рзЗ ржпрзМрждрзБржХ ржкрзНрж░ржерж╛рж░ ржмрж┐рж░рзЛржзрзАред

ржХрж▓рзНржпрж╛ржгрзА ржПржХржЬржи рждрж░рзБржгрзА ржпрж╛рж░ ржмрж┐ржпрж╝рзЗ ржЕрж▓рзНржк ржмржпрж╝рж╕рзЗ рж╣ржпрж╝рзЗржЫрж┐рж▓ред рждрж╛рж░ ржЪрж░рж┐рждрзНрж░рзЗ рж╕рзЗржЗ рж╕ржоржпрж╝рзЗрж░ ржирж╛рж░рзАржжрзЗрж░ ржЕржмрж╕рзНржерж╛ржи ржкрзНрж░рждрж┐ржлрж▓рж┐ржд рж╣ржпрж╝рзЗржЫрзЗред

рж╢рзБржорзНржнрзБржирж╛рже ржЕржирзБржкржорзЗрж░ ржЖржжрж░рзНрж╢ ржкрзБрж░рзБрж╖рзЗрж░ ржкрзНрж░рждрж┐ржорзВрж░рзНрждрж┐ред рждрж┐ржирж┐ рж╢рж┐ржХрзНрж╖рж┐ржд, ржЪрж░рж┐рждрзНрж░ржмрж╛ржи ржПржмржВ рж╕ржорж╛ржЬ рж╕ржЪрзЗрждржиред

рж╕рж╛ржорж╛ржЬрж┐ржХ ржкрзНрж░рзЗржХрзНрж╖рж╛ржкржЯ:
ржПржЗ ржЧрж▓рзНржкрзЗ ржмрж╛ржВрж▓рж╛рж░ рж╕рж╛ржорж╛ржЬрж┐ржХ рж░рзАрждрж┐-ржирзАрждрж┐, ржмрж┐ржмрж╛рж╣ ржкрзНрж░ржерж╛ ржПржмржВ рж╢рж┐ржХрзНрж╖рж┐ржд ржоржзрзНржпржмрж┐рждрзНржд рж╕ржорж╛ржЬрзЗрж░ ржЪрж┐рждрзНрж░ ржлрзБржЯрзЗ ржЙржарзЗржЫрзЗред
"""
    
    # Create data directory if it doesn't exist
    os.makedirs("data/pdfs", exist_ok=True)
    
    # Write sample content to a text file (simulating PDF content)
    with open("data/sample_bengali_content.txt", "w", encoding="utf-8") as f:
        f.write(sample_content)
    
    return "data/sample_bengali_content.txt"

def demo_text_processing():
    """Demonstrate text processing capabilities"""
    print("ЁЯУЪ Demo: Text Processing Capabilities")
    print("=" * 50)
    
    # Create sample content
    sample_file = create_sample_text_file()
    print(f"тЬЕ Created sample content: {sample_file}")
    
    # Initialize components
    from src.pdf_processor import PDFProcessor
    from src.text_chunker import TextChunker
    
    processor = PDFProcessor()
    chunker = TextChunker(chunk_size=300, chunk_overlap=50)
    
    # Read and process sample content
    with open(sample_file, "r", encoding="utf-8") as f:
        sample_text = f.read()
    
    # Generate statistics
    stats = processor.generate_stats(sample_text)
    print(f"\nЁЯУК Text Statistics:")
    print(f"   Total characters: {stats['total_characters']}")
    print(f"   Total words: {stats['total_words']}")
    print(f"   Bengali words: {stats['bengali_words']}")
    print(f"   Bengali percentage: {stats['bengali_percentage']:.1f}%")
    
    # Demonstrate chunking
    chunks = chunker.smart_chunk(sample_text, "sample_document")
    print(f"\nтЬВя╕П Text Chunking:")
    print(f"   Generated {len(chunks)} chunks")
    
    for i, chunk in enumerate(chunks[:3], 1):
        print(f"\n   Chunk {i}:")
        print(f"     Method: {chunk.metadata.get('chunk_method', 'unknown')}")
        print(f"     Length: {len(chunk.text)} characters")
        print(f"     Has Bengali: {chunk.metadata.get('has_bengali', False)}")
        print(f"     Text preview: {chunk.text[:100]}...")

def demo_rag_system():
    """Demonstrate RAG system capabilities"""
    print("ЁЯдЦ Demo: RAG System Capabilities")  
    print("=" * 50)
    
    # Initialize RAG system
    rag = MultilingualRAG()
    
    # Create sample content for knowledge base
    sample_file = create_sample_text_file()
    
    # Simulate PDF processing by directly adding text
    from src.text_chunker import TextChunker
    chunker = TextChunker()
    
    with open(sample_file, "r", encoding="utf-8") as f:
        sample_text = f.read()
    
    chunks = chunker.smart_chunk(sample_text, "sample_document")
    
    # Add chunks to vector database
    print("ЁЯФД Setting up knowledge base...")
    success = rag.vector_db.add_chunks(chunks)
    
    if success:
        print("тЬЕ Knowledge base setup successful!")
        
        # Test queries
        test_queries = [
            "ржЕржирзБржкржорзЗрж░ ржнрж╛рж╖рж╛ржпрж╝ рж╕рзБржкрзБрж░рзБрж╖ ржХрж╛ржХрзЗ ржмрж▓рж╛ рж╣ржпрж╝рзЗржЫрзЗ?",
            "ржХрж╛ржХрзЗ ржЕржирзБржкржорзЗрж░ ржнрж╛ржЧрзНржп ржжрзЗржмрждрж╛ ржмрж▓рзЗ ржЙрж▓рзНрж▓рзЗржЦ ржХрж░рж╛ рж╣ржпрж╝рзЗржЫрзЗ?", 
            "ржмрж┐ржпрж╝рзЗрж░ рж╕ржоржпрж╝ ржХрж▓рзНржпрж╛ржгрзАрж░ ржкрзНрж░ржХрзГржд ржмржпрж╝рж╕ ржХржд ржЫрж┐рж▓?",
            "Who is described as a good person by Anupam?"
        ]
        
        print(f"\nтЭУ Testing {len(test_queries)} queries:")
        
        for i, query in enumerate(test_queries, 1):
            print(f"\n{i}. Query: {query}")
            
            try:
                result = rag.query(query)
                print(f"   Language: {result['language']}")
                print(f"   Response: {result['response']}")
                print(f"   Chunks found: {result['metadata']['chunks_found']}")
                
                if result['retrieved_chunks']:
                    avg_sim = sum(c['similarity'] for c in result['retrieved_chunks']) / len(result['retrieved_chunks'])
                    print(f"   Avg similarity: {avg_sim:.3f}")
                    
            except Exception as e:
                print(f"   тЭМ Error: {e}")
    else:
        print("тЭМ Knowledge base setup failed!")

def demo_api_usage():
    """Demonstrate API usage with sample requests"""
    print("ЁЯМР Demo: API Usage Examples")
    print("=" * 50)
    
    print("To test the API, run these commands in separate terminals:")
    print()
    print("1. Start the API server:")
    print("   python main.py api")
    print()
    print("2. Test health endpoint:")
    print('   curl http://localhost:8000/health')
    print()
    print("3. Test query endpoint:")
    print('   curl -X POST "http://localhost:8000/query" \\')
    print('     -H "Content-Type: application/json" \\')
    print('     -d \'{"query": "ржЕржирзБржкржорзЗрж░ ржнрж╛рж╖рж╛ржпрж╝ рж╕рзБржкрзБрж░рзБрж╖ ржХрж╛ржХрзЗ ржмрж▓рж╛ рж╣ржпрж╝рзЗржЫрзЗ?"}\'')
    print()
    print("4. Get system stats:")
    print('   curl http://localhost:8000/stats')
    print()
    print("5. Access interactive documentation:")
    print("   Open http://localhost:8000/docs in your browser")

def demo_evaluation():
    """Demonstrate evaluation capabilities"""
    print("ЁЯУК Demo: Evaluation System")
    print("=" * 50)
    
    # Create sample content
    sample_file = create_sample_text_file()
    
    try:
        # Initialize RAG system with sample data
        rag = MultilingualRAG()
        
        # Add sample content to knowledge base
        from src.text_chunker import TextChunker
        chunker = TextChunker()
        
        with open(sample_file, "r", encoding="utf-8") as f:
            sample_text = f.read()
        
        chunks = chunker.smart_chunk(sample_text, "sample_document")
        success = rag.vector_db.add_chunks(chunks)
        
        if success:
            print("тЬЕ Knowledge base ready for evaluation")
            
            # Sample test cases
            test_cases = [
                {
                    "query": "ржЕржирзБржкржорзЗрж░ ржнрж╛рж╖рж╛ржпрж╝ рж╕рзБржкрзБрж░рзБрж╖ ржХрж╛ржХрзЗ ржмрж▓рж╛ рж╣ржпрж╝рзЗржЫрзЗ?",
                    "expected_answer": "рж╢рзБржорзНржнрзБржирж╛рже" 
                },
                {
                    "query": "ржХрж▓рзНржпрж╛ржгрзАрж░ ржмржпрж╝рж╕ ржХржд ржЫрж┐рж▓?",
                    "expected_answer": "рззрзл ржмржЫрж░"
                }
            ]
            
            print(f"\nЁЯзк Running evaluation with {len(test_cases)} test cases...")
            
            from src.evaluation import RAGEvaluator
            evaluator = RAGEvaluator(rag)
            
            results = evaluator.evaluate_test_set(test_cases)
            
            print("ЁЯУИ Evaluation Results:")
            summary = results['evaluation_summary']
            
            print(f"   Total queries: {summary['total_queries']}")
            print(f"   Languages tested: {list(summary['language_distribution'].keys())}")
            
            # Show individual results
            for i, result in enumerate(results['individual_results'], 1):
                print(f"\n   Test {i}:")
                print(f"     Query: {result['query']}")
                print(f"     Expected: {result['ground_truth']}")
                print(f"     Got: {result['predicted_answer']}")
                print(f"     Similarity: {result['metrics'].get('semantic_similarity', 0):.3f}")
                print(f"     Groundedness: {result['metrics'].get('groundedness', 0):.3f}")
        else:
            print("тЭМ Failed to set up knowledge base for evaluation")
            
    except Exception as e:
        print(f"тЭМ Evaluation demo failed: {e}")

def main():
    """Run all demonstrations"""
    print("ЁЯЪА Multilingual RAG System - Complete Demo")
    print("=" * 60)
    print(f"Demo started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # Run demonstrations
    try:
        demo_text_processing()
        print("\n" + "=" * 60 + "\n")
        
        demo_rag_system()
        print("\n" + "=" * 60 + "\n")
        
        demo_api_usage()
        print("\n" + "=" * 60 + "\n")
        
        demo_evaluation()
        print("\n" + "=" * 60 + "\n")
        
        print("тЬЕ All demonstrations completed successfully!")
        print()
        print("Next steps:")
        print("1. Add your Bengali PDF files to data/pdfs/")
        print("2. Set up your API keys in .env file")
        print("3. Run 'python main.py setup' to build knowledge base")
        print("4. Start interactive session with 'python main.py query'")
        print("5. Launch API server with 'python main.py api'")
        
    except Exception as e:
        print(f"тЭМ Demo failed: {e}")
        print("Make sure all dependencies are installed: pip install -r requirements.txt")

if __name__ == "__main__":
    main()
